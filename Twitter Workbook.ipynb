{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Workbook\n",
    "\n",
    "# Twitter Sentiment Analysis\n",
    "\n",
    "This notebook aims to predict whether a person does or does not intend to get the COVID-19 vaccine by looking at Tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T18:31:56.372148Z",
     "start_time": "2021-04-05T18:31:55.991493Z"
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import webbrowser\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import API\n",
    "\n",
    "import config\n",
    "\n",
    "# auth.set_access_token(access_token, access_token_secret)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T15:19:13.987951Z",
     "start_time": "2021-04-02T15:19:13.985662Z"
    }
   },
   "outputs": [],
   "source": [
    "callback_uri = 'oob'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T15:19:14.528430Z",
     "start_time": "2021-04-02T15:19:14.525488Z"
    }
   },
   "outputs": [],
   "source": [
    "auth = OAuthHandler(config.consumer_key, config.consumer_secret, callback_uri)\n",
    "auth.set_access_token(config.access_token, config.access_token_secret)\n",
    "# redirect_url = auth.get_authorization_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:50:25.672839Z",
     "start_time": "2021-04-01T20:50:25.529912Z"
    }
   },
   "outputs": [],
   "source": [
    "# webbrowser.open(redirect_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:50:25.678742Z",
     "start_time": "2021-04-01T20:50:24.989Z"
    }
   },
   "outputs": [],
   "source": [
    "# user_pin_input = input(\"What's the pin value? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:51:00.810502Z",
     "start_time": "2021-04-01T20:51:00.803291Z"
    }
   },
   "outputs": [],
   "source": [
    "# auth.get_access_token(user_pin_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T15:19:17.778293Z",
     "start_time": "2021-04-02T15:19:17.776032Z"
    }
   },
   "outputs": [],
   "source": [
    "api = API(auth, wait_on_rate_limit= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T15:19:18.852527Z",
     "start_time": "2021-04-02T15:19:18.428962Z"
    }
   },
   "outputs": [],
   "source": [
    "me = api.me()\n",
    "print(me.screen_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get text from your timeline into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:51:18.391879Z",
     "start_time": "2021-04-01T20:51:18.206486Z"
    }
   },
   "outputs": [],
   "source": [
    "my_timeline = api.home_timeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:51:19.232885Z",
     "start_time": "2021-04-01T20:51:19.230231Z"
    }
   },
   "outputs": [],
   "source": [
    "print(my_timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:51:26.705357Z",
     "start_time": "2021-04-01T20:51:26.700824Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = set()\n",
    "allowed_types = [str, int]\n",
    "tweet_data = []\n",
    "\n",
    "for status in my_timeline:\n",
    "#     print(status.text)\n",
    "#     print (type(vas(status)))\n",
    "    status_dict = dict(vars(status))\n",
    "    keys = status_dict.keys()\n",
    "    single_tweet_data = {}\n",
    "    for k in keys:\n",
    "        try:\n",
    "            v_type = type(status_dict['k'])\n",
    "        except:\n",
    "            v_type = None\n",
    "            \n",
    "        if v_type != None:\n",
    "            if v_type in allowed_types:\n",
    "                single_tweet_data[k] = status_dict[k]\n",
    "                columns.add(k)\n",
    "    tweets_data.append(single_tweet_data )\n",
    "        \n",
    "header_cols = list(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:51:27.884925Z",
     "start_time": "2021-04-01T20:51:27.870516Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tweet_data, columns= header_cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:51:38.636118Z",
     "start_time": "2021-04-01T20:51:38.052121Z"
    }
   },
   "outputs": [],
   "source": [
    "#. get_status?\n",
    "\n",
    "user = api.get_user('code')\n",
    "user_timeline = user.timeline()\n",
    "df2 = extract_timeline_as_df(user_timeline)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:51:35.188373Z",
     "start_time": "2021-04-01T20:51:35.183458Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_timeline_as_df(timeline_list):\n",
    "    columns = set()\n",
    "    allowed_types = [str, int]\n",
    "    tweets_data = []\n",
    "    for status in timeline_list:\n",
    "        status_dict = dict(vars(status))\n",
    "        keys = status_dict.keys()\n",
    "        single_tweet_data = {\"user\": status.user.screen_name, \"author\": status.author.screen_name}\n",
    "        for k in keys:\n",
    "            try:\n",
    "                v_type = type(status_dict[k])\n",
    "            except:\n",
    "                v_type = None\n",
    "            if v_type != None:\n",
    "                if v_type in allowed_types:\n",
    "                    single_tweet_data[k] = status_dict[k]\n",
    "                    columns.add(k)\n",
    "        tweets_data.append(single_tweet_data)\n",
    "\n",
    "\n",
    "    header_cols = list(columns)\n",
    "    header_cols.append('author')\n",
    "    df = pd.DataFrame(tweets_data, columns=header_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:50:25.689440Z",
     "start_time": "2021-04-01T20:50:25.003Z"
    }
   },
   "outputs": [],
   "source": [
    "df3 = extract_timeline_as_df(user_timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:50:25.690507Z",
     "start_time": "2021-04-01T20:50:25.005Z"
    }
   },
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:50:25.691497Z",
     "start_time": "2021-04-01T20:50:25.006Z"
    }
   },
   "outputs": [],
   "source": [
    "status_obj = api.get_status('1247966976951058433')\n",
    "status_obj.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:50:25.692441Z",
     "start_time": "2021-04-01T20:50:25.007Z"
    }
   },
   "outputs": [],
   "source": [
    "print(status_obj.geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:50:25.693296Z",
     "start_time": "2021-04-01T20:50:25.010Z"
    }
   },
   "outputs": [],
   "source": [
    "len(api.home_timeline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:50:25.694069Z",
     "start_time": "2021-04-01T20:50:25.011Z"
    }
   },
   "outputs": [],
   "source": [
    "other_user = 'therock'\n",
    "for i, status in enumerate(tweepy.Cursor(api.user_timeline, screen_name = other_user).items(20)):\n",
    "    print (i, status.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:50:25.694922Z",
     "start_time": "2021-04-01T20:50:25.012Z"
    }
   },
   "outputs": [],
   "source": [
    "api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:50:25.695986Z",
     "start_time": "2021-04-01T20:50:25.013Z"
    }
   },
   "outputs": [],
   "source": [
    "# query = '#vaccine'\n",
    "# api.search(q = query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:50:25.697069Z",
     "start_time": "2021-04-01T20:50:25.015Z"
    }
   },
   "outputs": [],
   "source": [
    "query = '#vaccine covid'\n",
    "for i, status in enumerate(tweepy.Cursor(api.search, q= query).items(50)):\n",
    "    print (i, status.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:51:53.837358Z",
     "start_time": "2021-04-01T20:51:53.834570Z"
    }
   },
   "outputs": [],
   "source": [
    "cursor = tweepy.Cursor(api.user_timeline, id= 'code', tweet_mode = 'extended').items(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:51:55.283304Z",
     "start_time": "2021-04-01T20:51:54.903967Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in cursor:\n",
    "    print(dir(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:52:15.101239Z",
     "start_time": "2021-04-01T20:52:15.098167Z"
    }
   },
   "outputs": [],
   "source": [
    "cursor = tweepy.Cursor(api.user_timeline, id= 'code', tweet_mode = 'extended').items(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:52:47.992726Z",
     "start_time": "2021-04-01T20:52:47.610368Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in cursor:\n",
    "    print(i.full_text, i.lang, i.geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:55:05.289395Z",
     "start_time": "2021-04-01T20:55:05.286422Z"
    }
   },
   "outputs": [],
   "source": [
    "cursor = tweepy.Cursor(api.search, q= 'vaccine', tweet_mode = 'extended').items(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:55:06.755655Z",
     "start_time": "2021-04-01T20:55:06.357473Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in cursor:\n",
    "    print(i.full_text, i.lang, i.geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:23:45.415267Z",
     "start_time": "2021-04-01T21:23:45.080720Z"
    }
   },
   "outputs": [],
   "source": [
    "number_of_tweets = 50\n",
    "tweets = []\n",
    "language = []\n",
    "time = []\n",
    "\n",
    "for i in tweepy.Cursor(api.search, q= 'vaccine covid -RT',  tweet_mode = 'extended', include_rts= False).items(number_of_tweets):\n",
    "    tweets.append(i.full_text)\n",
    "    language.append(i.lang)\n",
    "    time.append(i.created_at)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:23:46.465814Z",
     "start_time": "2021-04-01T21:23:46.462414Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'time': time, 'language': language, 'tweets': tweets})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:23:47.484663Z",
     "start_time": "2021-04-01T21:23:47.476774Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:04:43.503842Z",
     "start_time": "2021-04-01T21:04:43.499893Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[~df.tweets.str.contains('RT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:05:12.977087Z",
     "start_time": "2021-04-01T21:05:12.974432Z"
    }
   },
   "outputs": [],
   "source": [
    "df.reset_index(drop= True, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:39:37.721239Z",
     "start_time": "2021-04-01T21:39:37.716993Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('tweets.csv', mode= 'a', index= False, header= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:34:34.782648Z",
     "start_time": "2021-04-01T21:34:34.773133Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('tweets.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:37:43.669307Z",
     "start_time": "2021-04-01T21:37:43.303352Z"
    }
   },
   "outputs": [],
   "source": [
    "number_of_tweets = 5\n",
    "tweets = []\n",
    "language = []\n",
    "time = []\n",
    "\n",
    "for i in tweepy.Cursor(api.search, q= 'vaccine covid -RT',  tweet_mode = 'extended', include_rts= False).items(number_of_tweets):\n",
    "    tweets.append(i.full_text)\n",
    "    language.append(i.lang)\n",
    "    time.append(i.created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:37:56.057583Z",
     "start_time": "2021-04-01T21:37:56.049306Z"
    }
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'time': time, 'language': language, 'tweets': tweets})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:38:30.567016Z",
     "start_time": "2021-04-01T21:38:30.563062Z"
    }
   },
   "outputs": [],
   "source": [
    "df3.to_csv('tweets.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search 30 day tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to turn results into DataFrame\n",
    "def extract_text_as_df(text_list):\n",
    "    columns = set()\n",
    "    allowed_types = [str, int]\n",
    "    tweets_data = []\n",
    "    for status in text_list:\n",
    "        status_dict = dict(vars(status))\n",
    "        keys = status_dict.keys()\n",
    "        single_tweet_data = {\"author\": status.author.screen_name}\n",
    "        for k in keys:\n",
    "            try:\n",
    "                v_type = type(status_dict[k])\n",
    "            except:\n",
    "                v_type = None\n",
    "            if v_type != None:\n",
    "                if v_type in allowed_types:\n",
    "                    single_tweet_data[k] = status_dict[k]\n",
    "                    columns.add(k)\n",
    "        tweets_data.append(single_tweet_data)\n",
    "\n",
    "\n",
    "    header_cols = list(columns)\n",
    "    header_cols.append('author')\n",
    "    df = pd.DataFrame(tweets_data, columns=header_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T23:19:51.785007Z",
     "start_time": "2021-04-01T23:19:51.438306Z"
    }
   },
   "outputs": [],
   "source": [
    "query = 'vaccine covid -RT'\n",
    "results_30 = api.search_30_day('datacollection', query, maxResults= 10)\n",
    "# results_30\n",
    "old_results_df = extract_text_as_df(results_30)\n",
    "old_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T22:13:23.552431Z",
     "start_time": "2021-04-01T22:13:18.017332Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T15:20:00.461155Z",
     "start_time": "2021-04-02T15:20:00.426488Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T15:20:06.002568Z",
     "start_time": "2021-04-02T15:20:05.994391Z"
    }
   },
   "outputs": [],
   "source": [
    "lang_df = df.sort_values('language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T15:20:08.019351Z",
     "start_time": "2021-04-02T15:20:07.828114Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T15:20:08.948094Z",
     "start_time": "2021-04-02T15:20:08.657876Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize= (12, 8))\n",
    "lang_df.language.value_counts(normalize=True).plot(kind= 'barh')\n",
    "plt.title('Proportion of Languages Collected')\n",
    "plt.xlim(-.01, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T15:20:13.122991Z",
     "start_time": "2021-04-02T15:20:13.115004Z"
    }
   },
   "outputs": [],
   "source": [
    "lang_df.language.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T15:22:49.050148Z",
     "start_time": "2021-04-02T15:22:48.692536Z"
    }
   },
   "outputs": [],
   "source": [
    "# what are these languages? get table from url\n",
    "URL = 'https://developer.twitter.com/en/docs/twitter-for-websites/supported-languages'\n",
    "tables = pd.read_html(URL)\n",
    "print(\"There are : \",len(tables),\" tables\")\n",
    "print(tables[0])\n",
    "\n",
    "lang_table = tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T15:22:53.363407Z",
     "start_time": "2021-04-02T15:22:53.350527Z"
    }
   },
   "outputs": [],
   "source": [
    "# lang_table\n",
    "header_row = 0\n",
    "lang_table.columns = lang_table.iloc[header_row]\n",
    "lang_table = lang_table.drop(header_row)\n",
    "lang_table.reset_index(drop= True, inplace= True)\n",
    "lang_table.replace('English (default)', 'English', inplace= True)\n",
    "lang_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T15:25:42.447826Z",
     "start_time": "2021-04-02T15:25:42.443338Z"
    }
   },
   "outputs": [],
   "source": [
    "lang_table.to_csv('data/languages.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T15:46:33.982159Z",
     "start_time": "2021-04-02T15:46:33.972596Z"
    }
   },
   "outputs": [],
   "source": [
    "duped = df[df.duplicated(subset= 'tweets')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T15:49:49.571048Z",
     "start_time": "2021-04-02T15:49:49.568338Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T15:49:50.613245Z",
     "start_time": "2021-04-02T15:49:50.604534Z"
    }
   },
   "outputs": [],
   "source": [
    "duped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T15:53:38.426807Z",
     "start_time": "2021-04-02T15:53:38.417025Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "df.drop_duplicates(subset= 'tweets', keep= 'first', inplace= True)\n",
    "df.reset_index(drop= True, inplace= True)\n",
    "df.tweets.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T15:54:52.907824Z",
     "start_time": "2021-04-02T15:54:52.902869Z"
    }
   },
   "outputs": [],
   "source": [
    "df.tweets.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:01:18.156092Z",
     "start_time": "2021-04-02T16:01:18.145465Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df['language'] == 'und']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:03:23.631400Z",
     "start_time": "2021-04-02T16:03:23.626943Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['language'] != 'und']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:03:28.507886Z",
     "start_time": "2021-04-02T16:03:28.497926Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:20:47.381173Z",
     "start_time": "2021-04-02T16:20:47.377561Z"
    }
   },
   "outputs": [],
   "source": [
    "lang_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:22:12.558201Z",
     "start_time": "2021-04-02T16:22:12.548919Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:40:29.678460Z",
     "start_time": "2021-04-02T16:40:29.661836Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df.merge(lang_table, how= 'inner', left_on= 'language', right_on= 'Language code')\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:40:31.892645Z",
     "start_time": "2021-04-02T16:40:31.880114Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.drop(columns = ['language', 'Language code'], inplace= True)\n",
    "df2.rename(columns={'Name': 'language'}, inplace= True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:40:37.540734Z",
     "start_time": "2021-04-02T16:40:37.537360Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.rename(columns={'Name': 'language'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:41:38.226537Z",
     "start_time": "2021-04-02T16:41:38.219601Z"
    }
   },
   "outputs": [],
   "source": [
    "df2['time'] = pd.to_datetime(df2['time']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:41:39.602341Z",
     "start_time": "2021-04-02T16:41:39.592114Z"
    }
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:35:12.210595Z",
     "start_time": "2021-04-02T16:35:12.199871Z"
    }
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:44:37.443221Z",
     "start_time": "2021-04-02T16:44:37.440479Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:51:39.872983Z",
     "start_time": "2021-04-02T16:51:39.640312Z"
    }
   },
   "outputs": [],
   "source": [
    "# countplot that excludes English to see detail\n",
    "plt.figure(figsize= (10, 8))\n",
    "sns.countplot(y= 'language', data= df2, palette='autumn',\n",
    "              order= df2.language.value_counts().iloc[1:].index)\n",
    "plt.title('Count of Tweets, Excluding English', fontsize= 14)\n",
    "plt.xlabel('# of Tweets')\n",
    "plt.ylabel('Language')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove urls? https: http: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use textblob?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T18:26:52.737072Z",
     "start_time": "2021-04-04T18:26:52.681025Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('data/tweets_translated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T18:26:55.152195Z",
     "start_time": "2021-04-04T18:26:55.148236Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_df = df2[['time', 'tweets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T20:35:06.996434Z",
     "start_time": "2021-04-04T20:35:06.993943Z"
    }
   },
   "outputs": [],
   "source": [
    "trial_df = sentiment_df[20:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T20:35:13.144620Z",
     "start_time": "2021-04-04T20:35:13.137293Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "trial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T15:13:50.242332Z",
     "start_time": "2021-04-05T15:13:50.240081Z"
    }
   },
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from google.cloud import language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T18:27:44.271655Z",
     "start_time": "2021-04-04T18:27:44.264852Z"
    }
   },
   "outputs": [],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file('../GCP_service_account.json')\n",
    "# translate_client = translate.Client(credentials= credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T18:34:23.593226Z",
     "start_time": "2021-04-04T18:34:23.590910Z"
    }
   },
   "outputs": [],
   "source": [
    "# client = language.LanguageServiceClient()\n",
    "nlp_client = language.Client(credentials = credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T16:58:32.578127Z",
     "start_time": "2021-04-05T16:58:32.575055Z"
    }
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "magnitudes = []\n",
    "\n",
    "def getGoogleSentiments(txt):\n",
    "    document = nlp_client.document_from_text(txt)\n",
    "    \n",
    "    sent_analysis = document.analyze_sentiment()\n",
    "    sentiment = sent_analysis.sentiment\n",
    "    \n",
    "    score = sentiment.score\n",
    "    scores.append(score)\n",
    "    magnitude = sentiment.magnitude\n",
    "    magnitudes.append(magnitude)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add time delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T17:13:01.520241Z",
     "start_time": "2021-04-05T17:13:01.517176Z"
    }
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "magnitudes = []\n",
    "\n",
    "def getGoogleSentiments(txt):\n",
    "    document = nlp_client.document_from_text(txt)\n",
    "\n",
    "    time.sleep(5)\n",
    "    print('sleeping 1')\n",
    "    sent_analysis = document.analyze_sentiment()\n",
    "    time.sleep(5)\n",
    "    print('sleeping 2')\n",
    "    sentiment = sent_analysis.sentiment\n",
    "\n",
    "    score = sentiment.score\n",
    "    scores.append(score)\n",
    "    magnitude = sentiment.magnitude\n",
    "    magnitudes.append(magnitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T17:14:15.902401Z",
     "start_time": "2021-04-05T17:13:03.195336Z"
    }
   },
   "outputs": [],
   "source": [
    "trying = trial_df.tweets.apply(getGoogleSentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_client.document_from_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T19:09:07.660488Z",
     "start_time": "2021-04-04T19:09:07.657627Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_analysis(text):\n",
    "    document = nlp_client.document_from_text(text)\n",
    "    \n",
    "    sent_analysis = document.analyze_sentiment()\n",
    "#     print(dir(sent_analysis))\n",
    "    sentiment = sent_analysis.sentiment\n",
    "    \n",
    "    ent_analysis = document.analyze_entities()\n",
    "    entities = ent_analysis.entities\n",
    "    \n",
    "#     synt_analysis = document.synt_analysis()\n",
    "#     syntax = synt_analysis.syntax\n",
    "    \n",
    "    return sentiment, entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "# translate tweets into English\n",
    "for i in trial4_df.tweets.loc[:]:\n",
    "    \n",
    "    document = nlp_client.document_from_text(i)\n",
    "    sent_analysis = document.analyze_sentiment()\n",
    "    sentiment = sent_analysis.sentiment\n",
    "    \n",
    "    score = sentiment.score\n",
    "    magnitude = sentiment.magnitude\n",
    "    \n",
    "    result = translate_client.translate(i, target_language= 'en')\n",
    "    results[i] = result['translatedText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T19:09:10.773019Z",
     "start_time": "2021-04-04T19:09:10.518403Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# example_text = 'Is it not obvious that Python is the best programming language of them all?'\n",
    "# example_text = 'Concerning the use of aborted baby tissue in the J&amp;J Covid vaccine:\\n\\n“The J&amp;J vaccine has sparked debate among some religious communities because it was developed from stem cells obtained during two abortions decades ago.”\\n\\nEvil is still evil, even if it was decades ago.'\n",
    "example_text = '@Kit_Yates_Maths Tests\\n1. Vax deployment ✅✅\\n2. Vax reduces hospitalisation ✅✅\\n3. Infection rates unsubstantiated pressure on NHS ✅\\n4. Variants of concern ☑️\\n\\nSo not measured but very conservative \\nhttps://t.co/iVMKF2pPsF https://t.co/ta4t21HH9s'\n",
    "\n",
    "sentiment, entities = language_analysis(example_text)\n",
    "print(sentiment.score, sentiment.magnitude)\n",
    "print()\n",
    "for e in entities:\n",
    "    print (e.name, e.entity_type, e.metadata, e.salience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T14:06:57.471214Z",
     "start_time": "2021-04-05T14:06:57.461312Z"
    }
   },
   "outputs": [],
   "source": [
    "trial3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T15:00:52.106635Z",
     "start_time": "2021-04-05T15:00:52.103401Z"
    }
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "magnitudes = []\n",
    "\n",
    "def getGoogleSentiments(txt):\n",
    "    document = nlp_client.document_from_text(txt)\n",
    "    \n",
    "    sent_analysis = document.analyze_sentiment()\n",
    "    sentiment = sent_analysis.sentiment\n",
    "    \n",
    "    score = sentiment.score\n",
    "    scores.append(score)\n",
    "    magnitude = sentiment.magnitude\n",
    "    magnitudes.append(magnitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T15:08:18.352931Z",
     "start_time": "2021-04-05T15:08:18.350525Z"
    }
   },
   "outputs": [],
   "source": [
    "trial4_df = sentiment_df[50:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T15:00:59.770781Z",
     "start_time": "2021-04-05T15:00:58.527538Z"
    }
   },
   "outputs": [],
   "source": [
    "ans4 = trial4_df.tweets.apply(getGoogleSentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T15:02:29.488587Z",
     "start_time": "2021-04-05T15:02:29.485240Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trial4_df['Google Score'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T15:08:23.136373Z",
     "start_time": "2021-04-05T15:08:23.129041Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trial4_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T15:09:17.248067Z",
     "start_time": "2021-04-05T15:09:16.039846Z"
    }
   },
   "outputs": [],
   "source": [
    "trial4_df.tweets.apply(lambda x: getGoogleSentiments(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T15:09:18.487359Z",
     "start_time": "2021-04-05T15:09:18.481171Z"
    }
   },
   "outputs": [],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T14:47:14.331523Z",
     "start_time": "2021-04-05T14:47:14.327918Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(trial2_df)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T15:09:10.769059Z",
     "start_time": "2021-04-05T15:09:10.763633Z"
    }
   },
   "outputs": [],
   "source": [
    "#try this one\n",
    "res_df = pd.DataFrame(columns = ['GoogSc', 'GoogMag'])\n",
    "df_len = len(trial3_df)\n",
    "scores = []\n",
    "magnitudes = []\n",
    "\n",
    "def getGoogleSentiments(txt):\n",
    "    document = nlp_client.document_from_text(txt)\n",
    "    \n",
    "    sent_analysis = document.analyze_sentiment()\n",
    "    sentiment = sent_analysis.sentiment\n",
    "    \n",
    "    score = sentiment.score\n",
    "    scores.append(score)\n",
    "    magnitude = sentiment.magnitude\n",
    "    magnitudes.append(magnitude)\n",
    "    \n",
    "    res_df = [[scores, magnitudes]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T15:21:58.068743Z",
     "start_time": "2021-04-05T15:21:56.636429Z"
    }
   },
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(columns = ['GoogSc', 'GoogMag'])\n",
    "\n",
    "# translate tweets into English\n",
    "for i in trial4_df.tweets.loc[:]:\n",
    "    \n",
    "    document = nlp_client.document_from_text(i)\n",
    "    sent_analysis = document.analyze_sentiment()\n",
    "    sentiment = sent_analysis.sentiment\n",
    "    \n",
    "    score = sentiment.score\n",
    "    magnitude = sentiment.magnitude\n",
    "    \n",
    "#     result = translate_client.translate(i, target_language= 'en')\n",
    "    res_df[i] = [score, magnitude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T15:22:09.353593Z",
     "start_time": "2021-04-05T15:22:09.337603Z"
    }
   },
   "outputs": [],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T14:57:49.228753Z",
     "start_time": "2021-04-05T14:57:44.905274Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trial3_df.tweets.apply(getGoogleSentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T14:58:41.655691Z",
     "start_time": "2021-04-05T14:58:41.652003Z"
    }
   },
   "outputs": [],
   "source": [
    "df_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T14:57:53.514403Z",
     "start_time": "2021-04-05T14:57:53.508576Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial3_df.merge(res_df, left_on= 'tweet', right_on= res_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T13:34:27.621151Z",
     "start_time": "2021-04-05T13:34:27.618112Z"
    }
   },
   "outputs": [],
   "source": [
    "def getGoogleSentiments(txt):\n",
    "    document = nlp_client.document_from_text(txt)\n",
    "    \n",
    "    sent_analysis = document.analyze_sentiment()\n",
    "    sentiment = sent_analysis.sentiment\n",
    "    \n",
    "    score = sentiment.score\n",
    "    magnitude = sentiment.magnitude\n",
    "    \n",
    "    return np.array((score, magnitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T14:07:18.909599Z",
     "start_time": "2021-04-05T14:07:15.199976Z"
    }
   },
   "outputs": [],
   "source": [
    "answer = trial3_df['tweets'].apply(getGoogleSentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T14:34:02.615421Z",
     "start_time": "2021-04-05T14:34:02.611812Z"
    }
   },
   "outputs": [],
   "source": [
    "trial3_df.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T14:20:22.952277Z",
     "start_time": "2021-04-05T14:20:22.949492Z"
    }
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "mags = []\n",
    "\n",
    "for s, m in answer:\n",
    "    scores.append(s)\n",
    "    mags.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T14:24:09.675275Z",
     "start_time": "2021-04-05T14:24:09.671388Z"
    }
   },
   "outputs": [],
   "source": [
    "trial3_df['GooglesScores'].loc[:] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T14:24:20.710422Z",
     "start_time": "2021-04-05T14:24:20.695382Z"
    }
   },
   "outputs": [],
   "source": [
    "trial3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T14:18:19.009785Z",
     "start_time": "2021-04-05T14:18:18.998807Z"
    }
   },
   "outputs": [],
   "source": [
    "trial3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T13:38:09.478759Z",
     "start_time": "2021-04-05T13:38:09.462622Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trial2_df[['Google Score', 'Google Magnitude']] = trial2_df['tweets'].apply(getGoogleSentiments, axis= 1, result_type= 'expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T13:56:27.164757Z",
     "start_time": "2021-04-05T13:56:27.155455Z"
    }
   },
   "outputs": [],
   "source": [
    "trial2_df[['Google Score','Google Magnitude']] = trial2_df['tweets'].apply(lambda x: (x[0], x[1]) for x in getGoogleSentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T13:29:50.042451Z",
     "start_time": "2021-04-05T13:29:50.029740Z"
    }
   },
   "outputs": [],
   "source": [
    "trial2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T19:02:08.536073Z",
     "start_time": "2021-04-04T19:02:08.533333Z"
    }
   },
   "source": [
    "**score** of the sentiment ranges between -1.0 (negative) and 1.0 (positive) and corresponds to the overall emotional leaning of the text.\n",
    "\n",
    "**magnitude** indicates the overall strength of emotion (both positive and negative) within the given text, between 0.0 and +inf. Unlike score, magnitude is not normalized; each expression of emotion within the text (both positive and negative) contributes to the text's magnitude (so longer text blocks may have greater magnitudes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T20:36:38.270610Z",
     "start_time": "2021-04-04T20:36:38.267286Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i in trial_df.tweets:\n",
    "#     print(i)\n",
    "    \n",
    "result = {}\n",
    "\n",
    "for text in example_text:\n",
    "    sentiment, entities = language_analysis(text)\n",
    "    result['score'] = sentiment.score\n",
    "    result['magnitude'] = sentiment.magnitude\n",
    "    \n",
    "    for e in entities:\n",
    "        result['entity name'] = e.name\n",
    "        result['entity salience'] = e.salience\n",
    "        \n",
    "    google_nlp_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing it the hard way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T18:32:14.046778Z",
     "start_time": "2021-04-05T18:32:14.018208Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "import re \n",
    "from textblob import TextBlob\n",
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokens = []\n",
    "for sent in compare_list:\n",
    "    print(tweet_tokenizer.tokenize(sent))\n",
    "    tweet_tokens.append(tweet_tokenizer.tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T22:57:02.965751Z",
     "start_time": "2021-04-04T22:57:02.962960Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|(amp)\", \n",
    "                           \" \", tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T21:08:48.425335Z",
     "start_time": "2021-04-04T21:08:48.422416Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_tweet_sentiment(tweet):\n",
    "    analysis = TextBlob(clean_tweet(tweet))\n",
    "    if analysis.sentiment.polarity < 0:\n",
    "        return 'negative'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T22:56:54.533653Z",
     "start_time": "2021-04-04T22:56:54.531151Z"
    }
   },
   "outputs": [],
   "source": [
    "trial3_df = sentiment_df[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T22:57:06.269986Z",
     "start_time": "2021-04-04T22:57:06.265473Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_tweets = []\n",
    "\n",
    "for i in trial3_df.tweets:\n",
    "    cleaned = clean_tweet(i)\n",
    "    cleaned_tweets.append(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T22:57:08.895170Z",
     "start_time": "2021-04-04T22:57:08.891005Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T21:08:52.084914Z",
     "start_time": "2021-04-04T21:08:52.077612Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_nums = []\n",
    "\n",
    "for i in cleaned_tweets:\n",
    "    sent_nums = get_tweet_sentiment(i)\n",
    "    sentiment_nums.append(sent_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T21:08:52.768876Z",
     "start_time": "2021-04-04T21:08:52.765256Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T21:10:04.608122Z",
     "start_time": "2021-04-04T21:10:04.604701Z"
    }
   },
   "outputs": [],
   "source": [
    "trial_df['TBlob sent'] = sentiment_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T21:10:16.043326Z",
     "start_time": "2021-04-04T21:10:16.034459Z"
    }
   },
   "outputs": [],
   "source": [
    "trial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T21:15:19.219747Z",
     "start_time": "2021-04-04T21:15:19.210238Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_nummms = []\n",
    "\n",
    "for i in trial_df.tweets:\n",
    "    cleaned = clean_tweet(i)\n",
    "    sent_nums = get_tweet_sentiment(cleaned)\n",
    "    sentiment_nummms.append(sent_nums)\n",
    "    \n",
    "sentiment_nummms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T21:25:50.407991Z",
     "start_time": "2021-04-04T21:25:50.405518Z"
    }
   },
   "outputs": [],
   "source": [
    "trial2_df = sentiment_df[35:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T21:26:49.314796Z",
     "start_time": "2021-04-04T21:26:49.310407Z"
    }
   },
   "outputs": [],
   "source": [
    "trial2_df['tweets'] = trial2_df['tweets'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T21:27:22.286891Z",
     "start_time": "2021-04-04T21:27:22.284036Z"
    }
   },
   "outputs": [],
   "source": [
    "def getTextSubjectivity(txt):\n",
    "    return TextBlob(txt).sentiment.subjectivity\n",
    "\n",
    "def getTextPolarity(txt):\n",
    "    return TextBlob(txt).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T21:28:25.506307Z",
     "start_time": "2021-04-04T21:28:25.485744Z"
    }
   },
   "outputs": [],
   "source": [
    "trial2_df['Subjectivity'] = trial2_df['tweets'].apply(getTextSubjectivity)\n",
    "trial2_df['Polarity'] = trial2_df['tweets'].apply(getTextPolarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T21:30:07.592568Z",
     "start_time": "2021-04-04T21:30:07.571711Z"
    }
   },
   "outputs": [],
   "source": [
    "trial2_df['TB Sentiment'] = trial2_df['tweets'].apply(get_tweet_sentiment)\n",
    "trial2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing for google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T16:35:45.684973Z",
     "start_time": "2021-04-05T16:35:45.682482Z"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T16:49:06.274124Z",
     "start_time": "2021-04-05T16:49:06.271427Z"
    }
   },
   "outputs": [],
   "source": [
    "listl = [1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T16:49:43.090566Z",
     "start_time": "2021-04-05T16:49:25.067074Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(listl)):\n",
    "    print(i)\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T16:54:21.990233Z",
     "start_time": "2021-04-05T16:54:21.987721Z"
    }
   },
   "outputs": [],
   "source": [
    "def time_delay(i):\n",
    "    print('here we go')\n",
    "\n",
    "    print('here we are')\n",
    "\n",
    "    print('there it went')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T16:54:49.757575Z",
     "start_time": "2021-04-05T16:54:31.739841Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(listl)):\n",
    "    time.sleep(3)\n",
    "    time_delay(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T19:36:17.650976Z",
     "start_time": "2021-04-05T19:36:17.566768Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cassienutter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk import word_tokenize, TweetTokenizer, FreqDist\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re \n",
    "from textblob import TextBlob\n",
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T18:36:09.827905Z",
     "start_time": "2021-04-05T18:36:09.771882Z"
    }
   },
   "outputs": [],
   "source": [
    "dataf = pd.read_csv('data/tweets_translated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T18:36:33.794326Z",
     "start_time": "2021-04-05T18:36:33.791541Z"
    }
   },
   "outputs": [],
   "source": [
    "def cleanTweet(txt):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|(amp)\", \n",
    "                           \" \", txt).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T18:36:57.338090Z",
     "start_time": "2021-04-05T18:36:56.953084Z"
    }
   },
   "outputs": [],
   "source": [
    "dataf['tweets'] = dataf['tweets'].apply(cleanTweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T18:38:45.945969Z",
     "start_time": "2021-04-05T18:38:45.605175Z"
    }
   },
   "outputs": [],
   "source": [
    "data = dataf['tweets'].map(TweetTokenizer).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T19:17:17.082425Z",
     "start_time": "2021-04-05T19:17:17.068140Z"
    }
   },
   "outputs": [],
   "source": [
    "dataaa = dataf['tweets'].map(TweetTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T19:17:29.406795Z",
     "start_time": "2021-04-05T19:17:29.401980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        <nltk.tokenize.casual.TweetTokenizer object at...\n",
       "1        <nltk.tokenize.casual.TweetTokenizer object at...\n",
       "2        <nltk.tokenize.casual.TweetTokenizer object at...\n",
       "3        <nltk.tokenize.casual.TweetTokenizer object at...\n",
       "4        <nltk.tokenize.casual.TweetTokenizer object at...\n",
       "                               ...                        \n",
       "18570    <nltk.tokenize.casual.TweetTokenizer object at...\n",
       "18571    <nltk.tokenize.casual.TweetTokenizer object at...\n",
       "18572    <nltk.tokenize.casual.TweetTokenizer object at...\n",
       "18573    <nltk.tokenize.casual.TweetTokenizer object at...\n",
       "18574    <nltk.tokenize.casual.TweetTokenizer object at...\n",
       "Name: tweets, Length: 18575, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T18:51:54.745724Z",
     "start_time": "2021-04-05T18:51:52.653542Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens = dataf['tweets'].map(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T18:50:36.365070Z",
     "start_time": "2021-04-05T18:50:36.361918Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list += list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T18:52:37.527023Z",
     "start_time": "2021-04-05T18:52:37.520706Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [Concerning, the, use, of, aborted, baby, tiss...\n",
       "1        [imagine, an, animal, getting, the, covid, 19,...\n",
       "2        [Definition, of, a, microstate, Source, of, va...\n",
       "3        [If, I, ve, Had, COVID, 19, Do, I, Still, Need...\n",
       "4        [My, epidural, was, delayed, again, somehow, m...\n",
       "                               ...                        \n",
       "18570    [Umrah, can, be, performed, without, vaccinati...\n",
       "18571    [Nurse, busy, on, mobile, one, person, was, va...\n",
       "18572    [While, talking, on, the, phone, the, nurse, v...\n",
       "18573    [Covid, 19, Vaccine, Registration, Easy, way, ...\n",
       "18574    [of, course, the, number, says, something, now...\n",
       "Name: tweets, Length: 18575, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T19:12:54.937891Z",
     "start_time": "2021-04-05T19:12:54.932835Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concerning\n",
      "use\n",
      "aborted\n",
      "baby\n",
      "tissue\n",
      "j\n",
      "j\n",
      "covid\n",
      "vaccine\n",
      "the\n",
      "j\n",
      "j\n",
      "vaccine\n",
      "sparked\n",
      "debate\n",
      "among\n",
      "religious\n",
      "communities\n",
      "developed\n",
      "stem\n",
      "cells\n",
      "obtained\n",
      "two\n",
      "abortions\n",
      "decades\n",
      "ago\n",
      "evil\n",
      "still\n",
      "evil\n",
      "even\n",
      "decades\n",
      "ago\n",
      "imagine\n",
      "animal\n",
      "getting\n",
      "covid\n",
      "19\n",
      "vaccine\n",
      "b4\n",
      "human\n",
      "definition\n",
      "microstate\n",
      "source\n",
      "vaccine\n",
      "data\n"
     ]
    }
   ],
   "source": [
    "# for l in tokens[:3]:\n",
    "#     print([w.lower() for w in l])\n",
    "    \n",
    "    \n",
    "for l in tokens[:3]:\n",
    "    for w in l:\n",
    "        if w not in stopwords_list:\n",
    "            print(w.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T19:00:22.847737Z",
     "start_time": "2021-04-05T19:00:22.834955Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7713cbf72734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstopped_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-7713cbf72734>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstopped_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "stopped_data = [w.lower() for w in tokens[:] if w not in stopwords_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T19:15:22.396820Z",
     "start_time": "2021-04-05T19:15:21.441588Z"
    }
   },
   "outputs": [],
   "source": [
    "# stopped_data = [w.lower() for l in tokens for w in w if w not in stopwords_list]\n",
    "\n",
    "stopped_data = [w.lower() for l in tokens for w in l if w not in stopwords_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T19:59:43.385055Z",
     "start_time": "2021-04-05T19:59:43.382038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315170"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Frequency and bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T19:37:33.436229Z",
     "start_time": "2021-04-05T19:37:33.256105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vaccine', 17816),\n",
       " ('covid', 15696),\n",
       " ('19', 6095),\n",
       " ('i', 5619),\n",
       " ('get', 2851),\n",
       " ('the', 2266),\n",
       " ('people', 2142),\n",
       " ('vaccines', 1273),\n",
       " ('got', 1250),\n",
       " ('first', 1234),\n",
       " ('dose', 1202),\n",
       " ('getting', 1176),\n",
       " ('vaccinated', 1152),\n",
       " ('one', 1094),\n",
       " ('appointments', 1056),\n",
       " ('available', 1023),\n",
       " ('pfizer', 986),\n",
       " ('it', 941),\n",
       " ('new', 928),\n",
       " ('like', 927)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_freq = FreqDist(stopped_data)\n",
    "words_freq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T19:39:25.658169Z",
     "start_time": "2021-04-05T19:39:25.655999Z"
    }
   },
   "outputs": [],
   "source": [
    "#bigrams\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "tweets_finder = nltk.collocations.BigramCollocationFinder.from_words(stopped_data)\n",
    "tweets_scored = tweets_finder.score_ngrams(bigram_measures.raw_freq)\n",
    "\n",
    "# show top 10 bigrams\n",
    "tweets_scored[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/tweets_sentiment_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T20:15:30.214419Z",
     "start_time": "2021-04-05T20:15:30.211455Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def tokenize(tweet):\n",
    "    tknzr = TweetTokenizer(strip_handles=True, reduce_len=True, preserve_case=False)\n",
    "    return tknzr.tokenize(tweet)\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T20:12:37.287621Z",
     "start_time": "2021-04-05T20:12:37.284979Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words= 'english', tokenizer= tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['tweets']]\n",
    "y = data[['Google Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "276px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
